{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import chunk\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import os \n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings chunk\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_h5(h5_directory:str, verbose:bool, cluster_res:float, n_pcs:int):\n",
    "    '''\n",
    "    Automatically integrates h5 files in designated directory and reads it into the current workspace as scanpy adata\n",
    "    '''\n",
    "\n",
    "    # Access h5 directory information\n",
    "    samples = [] \n",
    "    os.chdir(h5_directory)\n",
    "    if verbose: print(f'Changed working directory to {os.getcwd()}')\n",
    "    n_samples = len(os.listdir())\n",
    "    if verbose: print(f'Found {n_samples} samples. Appending paths to sample list.')\n",
    "    for file in os.listdir():\n",
    "        samples.append(os.path.realpath(file))\n",
    "\n",
    "    # Preprocess h5 samples \n",
    "    adata_dict = {}\n",
    "    for sample in samples:\n",
    "        name = os.path.basename(sample)\n",
    "        if verbose: print(f'Preprocessing sample: {name}')\n",
    "        adata = pp(sample,n_pcs=n_pcs,cluster_res=cluster_res)\n",
    "        adata_dict[name] = adata\n",
    "        adata_dict[name].obs['batch'] = name\n",
    "\n",
    "    # Find intersections between samples we start with the sample with the most clusters\n",
    "    for adata in adata_dict.values():\n",
    "        n_clust = {}\n",
    "        name = np.unique(adata.obs['batch'])\n",
    "        print(name)\n",
    "        n_clust[name] = pd.unique(adata.obs['leiden'].shape[0]) # This is currently broken. Fix - DM \n",
    "        print(n_clust[name])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pp(h5_path,n_pcs,cluster_res):\n",
    "    '''\n",
    "    Standard preprocessing, from https://github.com/mousepixels/sanbomics_scripts/blob/main/simple_scanpy_integration.ipynb\n",
    "    '''\n",
    "    adata = sc.read_10x_h5(h5_path)\n",
    "    adata.var_names_make_unique()\n",
    "    sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes\n",
    "    sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells\n",
    "    adata.var['mt'] = adata.var_names.str.startswith('mt-')  # annotate the group of mitochondrial genes as 'mt'\n",
    "    sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "    upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98)\n",
    "    lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02)\n",
    "    adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]\n",
    "    adata = adata[adata.obs.pct_counts_mt < 20]\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI\n",
    "    sc.pp.log1p(adata) #change to log counts\n",
    "    sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values\n",
    "    adata.raw = adata #save raw data before processing values and further filtering\n",
    "    adata = adata[:, adata.var.highly_variable] #filter highly variable\n",
    "    sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed\n",
    "    sc.pp.scale(adata, max_value=10) #scale each gene to unit variance\n",
    "    sc.tl.pca(adata, svd_solver='arpack')\n",
    "    sc.pp.neighbors(adata, n_neighbors=10, n_pcs= n_pcs)\n",
    "    sc.tl.leiden(adata, resolution = cluster_res)\n",
    "    sc.tl.umap(adata)\n",
    "    return adata\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed working directory to /home/dm2763/projects/scenic/pyscenic/OE_final/Filtered_mtx/MOLNG2407\n",
      "Found 4 samples. Appending paths to sample list.\n",
      "Preprocessing sample: L34687\n",
      "Preprocessing sample: L34688\n",
      "Preprocessing sample: L34689\n",
      "Preprocessing sample: L34690\n",
      "['L34687']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mintegrate_h5\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/dm2763/projects/scenic/pyscenic/OE_final/Filtered_mtx/MOLNG2407\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_res\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_pcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[83], line 29\u001b[0m, in \u001b[0;36mintegrate_h5\u001b[0;34m(h5_directory, verbose, cluster_res, n_pcs)\u001b[0m\n\u001b[1;32m     27\u001b[0m name \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(adata\u001b[38;5;241m.\u001b[39mobs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(name)\n\u001b[0;32m---> 29\u001b[0m n_clust[name] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleiden\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(n_clust[name])\n",
      "File \u001b[0;32m~/micromamba/envs/pyscenic2/lib/python3.8/site-packages/pandas/core/algorithms.py:390\u001b[0m, in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(values):\n\u001b[1;32m    297\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03m    Return unique values based on a hash table.\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique_with_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/pyscenic2/lib/python3.8/site-packages/pandas/core/algorithms.py:418\u001b[0m, in \u001b[0;36munique_with_mask\u001b[0;34m(values, mask)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique_with_mask\u001b[39m(values, mask: npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    417\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"See algorithms.unique for docs. Takes a mask for masked arrays.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 418\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_arraylike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_extension_array_dtype(values\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    421\u001b[0m         \u001b[38;5;66;03m# Dispatch to extension dtype's unique.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39munique()\n",
      "File \u001b[0;32m~/micromamba/envs/pyscenic2/lib/python3.8/site-packages/pandas/core/algorithms.py:222\u001b[0m, in \u001b[0;36m_ensure_arraylike\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03mensure that we are arraylike if not already\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_array_like(values):\n\u001b[0;32m--> 222\u001b[0m     inferred \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inferred \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed-integer\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;66;03m# \"mixed-integer\" to ensure we do not cast [\"ss\", 42] to str GH#22160\u001b[39;00m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/micromamba/envs/pyscenic2/lib/python3.8/site-packages/pandas/_libs/lib.pyx:1494\u001b[0m, in \u001b[0;36mpandas._libs.lib.infer_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "integrate_h5('/home/dm2763/projects/scenic/pyscenic/OE_final/Filtered_mtx/MOLNG2407', cluster_res=0.5, n_pcs=50, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
